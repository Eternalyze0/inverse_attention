# inverse_attention
Inverse attention is robust to high learning rates.

```
learning_rate = 0.01:

inverse_attention:
step 2000: train loss 1.6163, val loss 1.7786

regular_attention:
nan

regular_attention on small learning rate:
step 2000: train loss 1.7236, val loss 1.8865
```
